"""Combined EPUB handling, processing, and validation."""

import zipfile
import tempfile
import shutil
from pathlib import Path
from lxml import etree
from bs4 import BeautifulSoup, NavigableString

from config import Config
from ..config import EPUBConfig
from logger_setup import get_logger
from chinese_converter.formats.base_handler import BaseFormatHandler

logger = get_logger(__name__, "chinese_converter")


class EPUBHandler(BaseFormatHandler):
    """Handles all EPUB operations: extraction, processing, validation, and creation."""

    def __init__(self, path: Path, converter):
        """Initialize with EPUB path and text converter."""
        super().__init__(path, converter)
        self.temp_dir = None

        if not self.path.exists():
            raise FileNotFoundError(f"EPUB not found: {path}")
        
    def process_file(self, input_path: Path, output_path: Path) -> bool:
        """Process EPUB file - implements BaseFormatHandler interface."""
        self.path = input_path
        
        if not self.path.exists():
            logger.error(f"EPUB not found: {input_path}")
            return False
        
        try:
            # Use existing process() method
            if self.process():
                # Use existing save_as() method
                return self.save_as(str(output_path))
            return False
        finally:
            self.cleanup()

    def validate_file(self, file_path: Path) -> tuple[bool, list]:
        """Validate EPUB file - implements BaseFormatHandler interface."""
        if not file_path.suffix.lower() == '.epub':
            return False, ["Not an EPUB file"]
        
        self.path = file_path
        return self.validate()

    def validate(self) -> tuple[bool, list]:
        """Validate EPUB structure."""
        errors = []

        try:
            with zipfile.ZipFile(self.path, "r") as zf:
                files = zf.namelist()

                if "mimetype" not in files:
                    errors.append("Missing mimetype file")

                if "META-INF/container.xml" not in files:
                    errors.append("Missing container.xml")

                # Check mimetype content
                try:
                    mimetype = zf.read("mimetype").decode("utf-8").strip()
                    if mimetype != "application/epub+zip":
                        errors.append(f"Invalid mimetype: {mimetype}")
                except Exception:
                    errors.append("Could not read mimetype")

        except zipfile.BadZipFile:
            errors.append("Invalid ZIP file")
        except Exception as e:
            errors.append(f"Validation error: {e}")

        return len(errors) == 0, errors

    def process(self) -> bool:
        """Extract, process, and recreate EPUB."""
        try:
            # Validate first
            valid, errors = self.validate()
            if not valid:
                logger.error(f"Invalid EPUB: {'; '.join(errors)}")
                return False

            # Extract
            self._extract()

            # Process files
            self._process_files()

            return True

        except Exception as e:
            logger.error(f"Processing failed: {e}")
            return False

    def save_as(self, output_path: str) -> bool:
        """Save processed EPUB to new file."""
        if not self.temp_dir:
            logger.error("No processed content to save")
            return False

        try:
            output_path = Path(output_path)
            output_path.parent.mkdir(parents=True, exist_ok=True)

            with zipfile.ZipFile(output_path, "w", zipfile.ZIP_DEFLATED) as zf:
                # Add mimetype first (uncompressed)
                mimetype_path = Path(self.temp_dir) / "mimetype"
                if mimetype_path.exists():
                    zf.write(
                        mimetype_path, "mimetype", compress_type=zipfile.ZIP_STORED
                    )

                # Add other files
                for file_path in Path(self.temp_dir).rglob("*"):
                    if file_path.is_file() and file_path.name != "mimetype":
                        archive_name = file_path.relative_to(self.temp_dir).as_posix()
                        zf.write(file_path, archive_name)

            logger.info(f"Saved EPUB: {output_path}")
            return True

        except Exception as e:
            logger.error(f"Failed to save EPUB: {e}")
            return False

    def _extract(self):
        """Extract EPUB to temp directory."""
        self.temp_dir = tempfile.mkdtemp(
            prefix=Config.TEMP_DIR_PREFIX, dir=Config.TEMP_DIRECTORY
        )

        with zipfile.ZipFile(self.path, "r") as zf:
            zf.extractall(self.temp_dir)

        logger.info(f"Extracted to: {self.temp_dir}")

    def _process_files(self):
        """Process all translatable files."""
        for file_path in Path(self.temp_dir).rglob("*"):
            if (
                file_path.is_file()
                and file_path.suffix.lower() in EPUBConfig.TRANSLATABLE_EXTENSIONS
            ):
                self._process_file(file_path)

    def _process_file(self, file_path: Path):
        """Process a single file based on its type."""
        try:
            extension = file_path.suffix.lower()
            name = file_path.name.lower()

            if extension == ".opf" or "content.opf" in name:
                self._process_opf(file_path)
            elif extension == ".ncx":
                self._process_ncx(file_path)
            elif extension in {".xhtml", ".html", ".htm"}:
                self._process_html(file_path)
            elif extension in {".xml", ".css"}:
                self._process_text_file(file_path)

            self.stats["files_processed"] += 1

        except Exception as e:
            logger.error(f"Error processing {file_path}: {e}")
            self.stats["errors"] += 1

    def _process_opf(self, file_path: Path):
        """Process OPF metadata file."""
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()

        root = etree.fromstring(content.encode("utf-8"))

        # Process metadata
        namespaces = {"dc": "http://purl.org/dc/elements/1.1/"}
        for xpath in [
            ".//dc:title",
            ".//dc:creator",
            ".//dc:description",
            ".//dc:subject",
        ]:
            for elem in root.xpath(xpath, namespaces=namespaces):
                if elem.text:
                    converted = self.converter.convert(elem.text)
                    if converted != elem.text:
                        elem.text = converted
                        self.stats["texts_converted"] += 1

        with open(file_path, "wb") as f:
            f.write(etree.tostring(root, encoding="utf-8", xml_declaration=True))

    def _process_ncx(self, file_path: Path):
        """Process NCX navigation file."""
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()

        root = etree.fromstring(content.encode("utf-8"))

        for elem in root.xpath(".//*[local-name()='text']"):
            if elem.text:
                converted = self.converter.convert(elem.text)
                if converted != elem.text:
                    elem.text = converted
                    self.stats["texts_converted"] += 1

        with open(file_path, "wb") as f:
            f.write(etree.tostring(root, encoding="utf-8", xml_declaration=True))

    def _process_html(self, file_path: Path):
        """Process HTML content files."""
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()

        soup = BeautifulSoup(content, "html.parser")

        # Process text nodes
        for text_node in soup.find_all(string=True):
            if isinstance(text_node, NavigableString) and text_node.strip():
                converted = self.converter.convert(str(text_node))
                if converted != str(text_node):
                    text_node.replace_with(converted)
                    self.stats["texts_converted"] += 1

        # Process attributes
        for tag in soup.find_all(attrs={"title": True}):
            converted = self.converter.convert(tag["title"])
            if converted != tag["title"]:
                tag["title"] = converted
                self.stats["texts_converted"] += 1

        for tag in soup.find_all(attrs={"alt": True}):
            converted = self.converter.convert(tag["alt"])
            if converted != tag["alt"]:
                tag["alt"] = converted
                self.stats["texts_converted"] += 1

        with open(file_path, "w", encoding="utf-8") as f:
            f.write(str(soup))

    def _process_text_file(self, file_path: Path):
        """Process generic text files (CSS, XML)."""
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()

        # Simple text conversion (works for CSS comments and XML text)
        converted_content = self.converter.convert(content)
        if converted_content != content:
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(converted_content)
            self.stats["texts_converted"] += 1

    def cleanup(self):
        """Clean up temp directory."""
        if self.temp_dir and Path(self.temp_dir).exists():
            shutil.rmtree(self.temp_dir, ignore_errors=True)
            self.temp_dir = None

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.cleanup()
